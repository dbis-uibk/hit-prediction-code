{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from hit_prediction_code.analytics import get_results_as_dataframe\n",
    "from hit_prediction_code import analytics\n",
    "\n",
    "results = get_results_as_dataframe(\n",
    "    project_name='hit-prediction-ismir2020',\n",
    "    table_name='hit_prediction',\n",
    "    filter_git_dirty=True,\n",
    "    date_filter='> \\'2021-08-04 16:20:00\\'',\n",
    "    columns=['id', 'date', 'sourcefile', 'outcome'],\n",
    "#     filters=['sourcefile LIKE \\'plans/hspd/regression_%%.py\\''],\n",
    "    filters=['sourcefile LIKE \\'plans/hspd/regression_cleaned%%_%%all_yanghitscore.py\\''],\n",
    "#     filters=['sourcefile LIKE \\'plans/ordinal%%\\''],\n",
    ")\n",
    "\n",
    "analytics.add_approach_to_df(results)\n",
    "analytics.add_cv_epoch_evaluator_outcome_to_df(results)\n",
    "\n",
    "results.sort_values(by='sourcefile', inplace=True)\n",
    "display(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results = []\n",
    "for _, row in results.iterrows():\n",
    "    metrics = list(filter(lambda i: i not in ['confusion_matrix'], row['mean'].index))\n",
    "    row = pd.DataFrame(pd.concat([row, row['mean'].loc[metrics].max(axis=1).abs()], axis=0)).transpose()\n",
    "\n",
    "    best_results.append(row)\n",
    "best_results = pd.concat(best_results)\n",
    "\n",
    "best_results['mae'] = best_results['neg_mean_absolute_error']\n",
    "best_results['meae'] = best_results['neg_median_absolute_error']\n",
    "best_results['rmse'] = best_results['neg_mean_squared_error'].pow(1./2)\n",
    "best_results = best_results.sort_values(by=['sourcefile'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_avg = analytics.aggregate_splits_per_epoch(results['outcome'], np.average)\n",
    "\n",
    "# display(analytics.aggregate_epochs(metric_avg, np.max).abs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results['approach'] = best_results['approach'].apply(lambda v: v.replace('mean_std', 'ms'))\n",
    "# display(best_results[['date', 'approach', 'mae', 'rmse', 'pearsonr', 'spearmanr', 'kendalltau']])\n",
    "display(best_results[['approach', 'spearmanr', 'kendalltau']])\n",
    "\n",
    "# display(best_results[['approach', 'mae']].plot.bar(x='approach', y='mae', title='Wide and Deep MAE', figsize=(12, 6)))\n",
    "# display(best_results[['approach', 'rmse']].plot.bar(x='approach', y='rmse', title='Wide and Deep RMSE', figsize=(12, 6)))\n",
    "\n",
    "# display(best_results[['approach', 'pearsonr']].plot.bar(x='approach', y='pearsonr', title='Wide and Deep Pearson Correlation', figsize=(12, 6)))\n",
    "display(best_results[['approach', 'spearmanr']].plot.bar(x='approach', y='spearmanr', title='Spearman Correlation', figsize=(12, 6)))\n",
    "display(best_results[['approach', 'kendalltau']].plot.bar(x='approach', y='kendalltau', title='Kendall Correlation', figsize=(12, 6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_names = list(filter(lambda e: e.startswith('split-'), result2.index))\n",
    "\n",
    "splits1 = []\n",
    "for split in split_names:\n",
    "    splits1.append(results.iloc[1][split]['1'].loc['spearmanr'])\n",
    "\n",
    "splits2 = []\n",
    "for split in split_names:\n",
    "    splits2.append(results.iloc[4][split]['300'].loc['spearmanr'])\n",
    "    \n",
    "num_samples = 10**4\n",
    "sample_size = 50\n",
    "    \n",
    "sample_means1 = []\n",
    "for _ in range(num_samples):\n",
    "    sample_mean = np.random.choice(splits1, size=sample_size).mean()\n",
    "    sample_means1.append(sample_mean)\n",
    "    \n",
    "sample_means2 = []\n",
    "for _ in range(num_samples):\n",
    "    sample_mean = np.random.choice(splits2, size=sample_size).mean()\n",
    "    sample_means2.append(sample_mean)\n",
    "    \n",
    "print(splits1)\n",
    "print(splits2)\n",
    "\n",
    "print('0.4326', '0.4393', '', sep='\\n')\n",
    "print(np.mean(sample_means1))\n",
    "print(np.mean(sample_means2))\n",
    "    \n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(color_codes=True)\n",
    "sns.set(rc={'figure.figsize': (20,10)})\n",
    "plt.title('Bootstrap', fontsize='25')\n",
    "plt.xlabel('Score', fontsize='20')\n",
    "plt.ylabel('Score Frequency', fontsize='20')\n",
    "sns.distplot(sample_means1)\n",
    "sns.distplot(sample_means2)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
