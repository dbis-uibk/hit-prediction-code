{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-ferry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HSPd\n",
    "\n",
    "## Last.fm Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-quality",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from collections import defaultdict\n",
    "import os.path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "lfm_files = glob.glob('../../data/hit_song_prediction_lastfm/sample/*.pickle')\n",
    "\n",
    "\n",
    "def merge_features(cols):\n",
    "    cols = map(lambda c: '.'.join(str(c).split('.')[:2]), cols)\n",
    "    cols = sorted(list(set(cols)))\n",
    "    \n",
    "    return cols\n",
    "    \n",
    "ess_lfm_features = None\n",
    "for f in lfm_files:\n",
    "    columns = list(filter(lambda c: not c.startswith('metadata') ,pd.read_pickle(f).columns))\n",
    "    columns = merge_features(columns)\n",
    "    \n",
    "    if 'melspect' not in f:\n",
    "        if ess_lfm_features:\n",
    "            ess_lfm_features.intersection_update(set(columns))\n",
    "        else:\n",
    "            ess_lfm_features = set(columns)\n",
    "\n",
    "ess_f = sorted(list(filter(lambda f: (f.startswith('highlevel') or f.startswith('lowlevel') or f.startswith('rhythm') or f.startswith('tonal')), ess_lfm_features)))\n",
    "\n",
    "feat = defaultdict(list)\n",
    "for f in ess_f:\n",
    "    f = f.split('.')\n",
    "    feat[f[0]].append(f[1])\n",
    "    \n",
    "display(dict(feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-vertical",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os.path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "cleaned_files = glob.glob('../../data/hit_song_prediction_ismir2020/sample/*.pickle')\n",
    "cleaned_files = list(filter(lambda f: 'cleaned' in f, cleaned_files))\n",
    "    \n",
    "ess_cleaned_features = None\n",
    "for f in cleaned_files:\n",
    "    columns = list(filter(lambda c: not str(c).startswith('metadata') ,pd.read_pickle(f).columns))\n",
    "    columns = merge_features(columns)\n",
    "    \n",
    "    if 'melspect' not in f:\n",
    "        if ess_cleaned_features:\n",
    "            ess_cleaned_features.intersection_update(set(columns))\n",
    "        else:\n",
    "            ess_cleaned_features = set(columns)\n",
    "            \n",
    "display(ess_cleaned_features - ess_lfm_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-motorcycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet('../../data/hit_song_prediction_ismir2020/processed/msd_bb_mbid_cleaned_matches_ab_unique.parquet')\n",
    "\n",
    "matches = pd.read_csv('../../data/hit_song_prediction_ismir2020/interim/msd_bb_mbid_cleaned_matches.csv')[['uuid', 'msd_id']]\n",
    "non_matches = pd.read_csv('../../data/hit_song_prediction_ismir2020/interim/msd_bb_mbid_non_matches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-banks",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = pd.concat([matches[['uuid', 'msd_id']], non_matches[['uuid', 'msd_id']]]).drop_duplicates()\n",
    "\n",
    "msd_year = pd.read_csv('../../data/millionsongdataset/additional_files/tracks_per_year.txt', sep='<SEP>', names=['year', 'msd_id', 'artist', 'title'])[['year', 'msd_id']]\n",
    "\n",
    "mapping_year = mapping.merge(msd_year, on=['msd_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-duplicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "uuid_year = mapping_year[['uuid', 'year']].groupby(by='uuid').agg(lambda x : x.max() == x.min())\n",
    "uuid_year = uuid_year[uuid_year['year']].reset_index()[['uuid']]\n",
    "\n",
    "display(uuid_year.shape, uuid_year[['uuid']].drop_duplicates().shape)\n",
    "\n",
    "\n",
    "cor_year = uuid_year[['uuid']].drop_duplicates().merge(mapping_year[['uuid', 'year']].drop_duplicates(), on=['uuid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-order",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape, data.merge(cor_year, on=['uuid']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-hobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "some = mapping_year[['uuid', 'year']].groupby(by='uuid').agg([lambda x : x.max() == x.min(), np.min, np.max])\n",
    "some[some[('year', '<lambda_0>')] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-prime",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lfm = pd.read_parquet('../../data/hit_song_prediction_lastfm/processed/msd_lastfm_matches_ab_unique.parquet')\n",
    "matches_lfm = pd.read_csv('../../data/hit_song_prediction_lastfm/interim/msd_lastfm_matches.csv')[['uuid', 'msd_id']].drop_duplicates()\n",
    "\n",
    "mapping_year_lfm = matches_lfm.merge(msd_year, on=['msd_id'])\n",
    "\n",
    "uuid_year_lfm = mapping_year_lfm[['uuid', 'year']].groupby(by='uuid').agg(lambda x : x.max() == x.min())\n",
    "uuid_year_lfm = uuid_year_lfm[uuid_year_lfm['year']].reset_index()[['uuid']]\n",
    "\n",
    "display(uuid_year_lfm.shape, uuid_year_lfm.drop_duplicates().shape)\n",
    "\n",
    "\n",
    "cor_year_lfm = uuid_year_lfm[['uuid']].drop_duplicates().merge(mapping_year_lfm[['uuid', 'year']].drop_duplicates(), on=['uuid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-production",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lfm.shape, data_lfm.merge(cor_year_lfm, on=['uuid']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-journal",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lfm.shape, data_lfm['uuid'].drop_duplicates().shape, cor_year_lfm.shape, cor_year_lfm.drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-treat",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lfm[['lastfm_playcount', 'lastfm_listener_count']], data[['lastfm_playcount', 'lastfm_listener_count']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
